# 3D Human Pose Estimation Based on Multi-view Feature Fusion and Dynamic Voxelization
To enhance the performance of 3D human pose estimation under occlusion, we propose an end-to-end algorithm based on feature fusion and dynamic voxelization. In the skeletal information extraction phase, we introduce a channel-wise graph convolution attention module to integrate multi-view image input, performing feature fusion between adjacent joint nodes at the channel level based on the initial features extracted by the 2D network. Subsequently, we adopt three feature fusion approaches to combine the spatial feature fusion module with the polar information from corresponding camera perspectives. In the 3D skeletal reconstruction phase, we leverage a branch network to learn the approximate coordinates of root nodes and back-project the fused heatmaps into the three-dimensional space, generating dynamic voxels. We further employ intermediate supervision loss to reduce the error of these voxels during the iterative sampling process in the 3D network to generate 3D joint nodes. Experimental results confirm the efficacy of our method on the Human3.6m dataset, achieving superior performance.
